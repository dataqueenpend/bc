## Wnioski

- Najczęściej stosowane techniki to: klasyfikacje binarne i ekstrakcja/klasteryzacja fraz, często łączone z LLM do oceny/podsumowań.
- Silna obecność tagów wektorowych i retrieval sugeruje potrzebę utrzymania oraz rozwoju indeksów (produkty, oświadczenia, tematy, skrypty).
- Obszary sprzedażowe (Wzrost sprzedaży) korzystają intensywnie z tagów technik językowych (obiekcje, CTA) oraz ewaluacji jakości (scoring), co wskazuje na dobre warunki do A/B oraz analizy uplift.
- Wątki compliance/obowiązki informacyjne mają komponenty checklist/retrieval – dobre kandydaty do automatycznego audytu i alertowania.
- Warto rozważyć ujednolicenie kilku wariantów tagów (np. pair-classification-agent-client vs client-agent) i utrzymywanie „słownika” tagów technicznych.

Rekomendacje operacyjne:
- Zbudować słownik tagów technicznych i politykę wersjonowania (mapowania stary->nowy) dla spójności w czasie.
- W raportowaniu przyjąć standardowy pivot: wiersze = projekty / zespoły, kolumny = tagi techniczne (one-hot), wartości = liczność.
- Dla zadań z retrieval+baza-wektorowa: utrzymywać metryki jakości (recall@k, MRR) i wersjonowanie indeksów.# One-hot dla tagów technicznych
pivot = unified.copy()
for t in tech_tags_df['tag']:
    pivot[t] = pivot['TAI - tagi'].fillna('').apply(lambda s: 1 if t in [x.strip() for x in s.split(',')] else 0)

# Przykładowe przekroje: po zespole i KPI
agg_by_team = pivot.groupby('Zespół zgłaszający potrzebę')[tech_tags_df['tag']].sum().sort_index()
agg_by_kpi = pivot.groupby('KPI')[tech_tags_df['tag']].sum().sort_index()

agg_by_team.head(), agg_by_kpi.head()## Tabele przestawne pod kątem tagów technicznych

cnt = Counter(all_tags)
tags_df = pd.DataFrame(cnt.most_common(), columns=['tag', 'liczba'])

is_tech = tags_df['tag'].apply(is_technical_tag)
tech_tags_df = tags_df[is_tech].reset_index(drop=True)
nontech_tags_df = tags_df[~is_tech].reset_index(drop=True)

print('Unikalnych tagów:', len(tags_df))
print(' — technicznych:', len(tech_tags_df))
print(' — nietechnicznych:', len(nontech_tags_df))

display(tags_df.head(20))
display(tech_tags_df.head(20))## Statystyki tagów
bc_path = base/'TAGI_BC_ODZ.csv'

tagibc_out = base/'tagi_BC.csv'
legenda_out = base/'legenda.csv'
pivot_out = base/'pivot.csv'

pd.set_option('display.max_colwidth', 200)

# Utils

def norm_space(s: str) -> str:
    if pd.isna(s):
        return ''
    s = str(s)
    s = s.replace('\ufeff','').replace('\xa0',' ')
    s = re.sub(r'\s+', ' ', s)
    return s.strip()

def strip_accents(text: str) -> str:
    if not isinstance(text, str):
        text = '' if pd.isna(text) else str(text)
    normalized = unicodedata.normalize('NFKD', text)
    return ''.join(ch for ch in normalized if not unicodedata.combining(ch))

TAG_MAP = {
    'pair-classfication': 'pair-classification',
    'pair-classfication-client-agent': 'pair-classification-client-agent',
    'karta kredytowa': 'karta-kredytowa',
    'baza-wektorowa-oświadczenia(procedury)': 'baza-wektorowa-oswiadczenia',
    'baza-wektorowa-oświadczenia': 'baza-wektorowa-oswiadczenia',
    'baza-wektorowa-oswiadczenia(procedury)': 'baza-wektorowa-oswiadczenia',
    'llm-klasyfikacja→skala': 'llm-klasyfikacja-skala',
}

TECHNICAL_STEMS = [
    'frazy-', 'llm-', 'baza-wektorowa', 'retrieval', 'reranking', 'diarization', 'timeline', 'dashboard', 'agent',
    'topic-modeling', 'sentiment', 'sentyment', 'ner', 'classification', 'klasyfikacja', 'clustering', 'checklista',
    'heatmap', 'emotion', 'pattern', 'contrastive', 'index', 'wyszukiwarka', 'highlight', 'facety', 'nlg', 'uplift',
    'scoring', 'audyt', 'human-in-the-loop', 'threshold', 'consistency-check', 'join-z-crm', 'free-text',
    'suggestion-engine', 'fcr-prediction', 'dominujacy-temat', 'multi-channel-klasyfikacja', 'indeks-metadanych'
]

NON_TECHNICAL_EXACT = set([
    'karta-kredytowa','kredyt-got','kredyt-hip','limit','ubezpieczenia','ubezpieczenie','promocje','select','retencja','kampania',
    'nps','fcr','csat','sl','bik','jdg','opinie','rezygnacja','select/pb','pb','vb','service','jakosc','compliance','kyc',
    'obiekcje','konsolidacja','konto-dziecka','konto-osobiste','tajemniczy-klient','reklamacje','edukacja','bezpieczenstwo',
    'fraud','segmentacja','segmentacja-rozmowy','segmentacja-procesow','kredyt','kwota','rata','oppt','przelewy','zalety',
    'ofertowanie','utrzymanie','finalizacja','retencja','select','opinie'
])

def normalize_tags(tag_str: str) -> str:
    if not isinstance(tag_str, str) or not tag_str.strip():
        return ''
    parts = [p.strip() for p in tag_str.split(',')]
    norm_parts, seen = [], set()
    for p in parts:
        if not p:
            continue
        token = p.strip().strip('"').replace('  ', ' ')
        token = token.replace('–', '-').replace('—', '-').replace('•', '-')
        token = token.replace(' :', ':').replace(': ', ':').replace(' + ', '+')
        if ' ' in token and not ('reranking' in token or 'retrieval' in token):
            token = token.replace(' ', '-')
        token = token.lower()
        token = TAG_MAP.get(token, token)
        token = strip_accents(token)
        token = re.sub(r'-{2,}', '-', token)
        token = token.strip(' ,;')
        if token and token not in seen:
            seen.add(token)
            norm_parts.append(token)
    return ', '.join(norm_parts)

def is_technical_tag(tag: str) -> bool:
    if not tag:
        return False
    base = strip_accents(tag.strip().lower())
    if base in NON_TECHNICAL_EXACT:
        return False
    return any(stem in base for stem in TECHNICAL_STEMS)

# Load
voice_df = pd.read_csv(voice_path)
bc_df = pd.read_csv(bc_path)

voice_df.columns = [norm_space(c) for c in voice_df.columns]
bc_df.columns = [norm_space(c) for c in bc_df.columns]

# Map to unified schema
OUTPUT_COLS = [
    'Zespół zgłaszający potrzebę','Projekt','Cel biznesowy','KPI','Opis problemu','Opis badania',
    'Korzyść dla Banku/Obszaru/Zespołu','TAI - refined_zadania','TAI - tagi','TAI - uwagi','TAI - tok myslenia','Dodatkowe'
]

# Voice mapping
v = pd.DataFrame({
    'Zespół zgłaszający potrzebę': voice_df.get('Zespół zgłaszający potrzebę',''),
    'Projekt': voice_df.get('Projekt',''),
    'Cel biznesowy': voice_df.get('Cel biznesowy',''),
    'KPI': voice_df.get('KPI',''),
    'Opis problemu': voice_df.get('Opis',''),
    'Opis badania': voice_df.get('TAI - refined_zadania','').fillna(voice_df.get('TAI - refined zadania','')),
    'Korzyść dla Banku/Obszaru/Zespołu': voice_df.get('Korzyść dla Banku/Obszaru/Zespołu',''),
    'TAI - refined_zadania': voice_df.get('TAI - refined_zadania','').fillna(voice_df.get('TAI - refined zadania','')),
    'TAI - tagi': voice_df.get('TAI - tagi','').map(normalize_tags),
    'TAI - uwagi': voice_df.get('TAI - uwagi',''),
    'TAI - tok myslenia': voice_df.get('TAI - tok myslenia',''),
    'Dodatkowe': voice_df.get('dodatkowe',''),
})

# Fill tok myslenia for voice as needed

def generate_tok_myslenia(tags_str: str, uwagi: str) -> str:
    tags = [t.strip() for t in tags_str.split(',')] if isinstance(tags_str, str) and tags_str else []
    def has(prefix):
        return any(t.startswith(prefix) for t in tags)
    if any(t == 'frazy-binaryx2' for t in tags):
        steps = [
            '1) Zdefiniować dwa klasyfikatory binarne wraz z kryteriami;',
            '2) Oznaczyć i zweryfikować na próbkach; kalibracja progów;',
            '3) Agregacja wyników i raportowanie KPI.'
        ]
    elif any(t == 'frazy-binary' for t in tags) and (has('frazy-ekstrakcja') or has('frazy-clustering')):
        steps = [
            '1) Klasyfikacja binarna rozmów pod kątem zjawiska;',
            '2) Ekstrakcja charakterystycznych fraz;',
            '3) Klasteryzacja/wzorce i porównanie vs KPI;',
            '4) Raport i rekomendacje.'
        ]
    elif has('baza-wektorowa') or has('retrieval'):
        steps = [
            '1) Przygotować bazę odniesienia (słownik/wektorowa) i przykłady;',
            '2) Retrieval (+ reranking) i porównanie do wzorca;',
            '3) Kalibracja progów i walidacja jakości;',
            '4) Agregacja, raport i monitoring.'
        ]
    elif has('pair-classification'):
        steps = [
            '1) Przygotować pary wypowiedzi (klient↔doradca);',
            '2) Zbudować klasyfikator relacji/reakcji;',
            '3) Ewaluacja i raportowanie.'
        ]
    elif has('llm-'):
        steps = [
            '1) Zdefiniować kryteria oceny/opisu;',
            '2) Zastosować LLM na próbkach i skalować;',
            '3) Walidacja wyników i konsolidacja wniosków.'
        ]
    else:
        steps = [
            '1) Zdefiniować kryteria i etykiety;',
            '2) Detekcja/etykietowanie przypadków;',
            '3) Agregacja i walidacja vs KPI.'
        ]
    return ' '.join(steps)

v['TAI - tok myslenia'] = v.apply(lambda r: r['TAI - tok myslenia'] if isinstance(r['TAI - tok myslenia'], str) and r['TAI - tok myslenia'].strip() else generate_tok_myslenia(r['TAI - tagi'], r['TAI - uwagi']), axis=1)

# BC mapping

def infer_cel_biznesowy(kpi: str, typ: str) -> str:
    k = (kpi or '').lower()
    t = strip_accents((typ or '').lower())
    if 'sr' in k or 'sv' in k:
        return 'Wzrost sprzedaży'
    if ('nps' in k) and (('fcr' in k) or ('csat' in k) or ('sat' in k)):
        return 'Poprawa wskaźników jakościowych FCR/NPS/Sat NET'
    if 'nps' in k:
        return 'NPS'
    if 'sl' in k:
        return 'SL'
    if 'proces' in t:
        return 'Optymalizacja procesu'
    if 'kontrola' in t:
        return 'Kontrola jakości'
    if 'biznes' in t:
        return 'Wzrost sprzedaży'
    return ''

problem = bc_df.get('PROBLEM','').fillna(bc_df.get('PROBLEM ','')).fillna(bc_df.get('PROBLEM\xa0',''))
opis_badamy = bc_df.get('OPIS- CO BADAMY','').fillna(bc_df.get('OPIS- CO BADAMY ','')).fillna(bc_df.get('OPIS- CO BADAMY\xa0',''))

b = pd.DataFrame({
    'Zespół zgłaszający potrzebę': bc_df.get('STRUMIEŃ',''),
    'Projekt': bc_df.get('NAZWA - PROJEKT',''),
    'KPI': bc_df.get('KPI',''),
    'Cel biznesowy': [infer_cel_biznesowy(k, t) for k, t in zip(bc_df.get('KPI',''), bc_df.get('TYP (BIZNES/PROCES/KONTROLA)',''))],
    'Opis problemu': problem,
    'Opis badania': opis_badamy,
    'Korzyść dla Banku/Obszaru/Zespołu': bc_df.get('KORZYŚCIE DLA BANKU/OBSZARU/ZESPOŁU',''),
    'TAI - refined_zadania': bc_df.get('TAI-refined zadania',''),
    'TAI - tagi': bc_df.get('TAI-tagi','').map(normalize_tags),
    'TAI - uwagi': bc_df.get('TAI-uwagi',''),
    'TAI - tok myslenia': '',
    'Dodatkowe': ''
})

b['TAI - tok myslenia'] = b.apply(lambda r: generate_tok_myslenia(r['TAI - tagi'], r['TAI - uwagi']), axis=1)

# Unified
unified = pd.concat([v, b], ignore_index=True)

# Save outputs
unified.to_csv(tagibc_out, index=False)

# Legend and technical one-hot
all_tags = []
for s in unified['TAI - tagi'].fillna(''):
    all_tags += [t.strip() for t in s.split(',') if t.strip()]

unique_tags = []
seen = set()
for t in all_tags:
    if t not in seen:
        seen.add(t)
        unique_tags.append(t)

technical_tags = [t for t in unique_tags if is_technical_tag(t)]

legenda = pd.DataFrame({'tag': technical_tags, 'opis': 'Tag techniczny używany w analizie rozmów.'})
# add curated descriptions
legenda_map = {
    'frazy-binary': 'Klasyfikacja binarna wystąpienia zjawiska na podstawie fraz/regex/ML.',
    'frazy-binaryx2': 'Dwie niezależne klasyfikacje binarne w jednym zadaniu.',
    'frazy-ekstrakcja': 'Ekstrakcja fraz/segmentów istotnych semantycznie z transkrypcji.',
    'frazy-clustering': 'Grupowanie podobnych fraz w klastry/tematy.',
    'pair-classification-client-agent': 'Klasyfikacja relacji/par wypowiedzi klient↔doradca.',
    'pair-classification-agent-client': 'Klasyfikacja relacji/par wypowiedzi agent↔klient.',
    'llm-podsumowanie': 'Użycie LLM do generowania podsumowań.',
    'llm-opis-segment': 'Użycie LLM do opisu/charakteryzacji segmentów.',
    'llm-opis-ocena': 'Użycie LLM do oceny jakości/argumentacji.',
    'retrieval+reranking': 'Wyszukiwanie wektorowe/BM25 z rerankingiem.',
    'retrieval': 'Wyszukiwanie informacji (IR) w bazach wiedzy.',
    'baza-wektorowa-tematy': 'Indeks wektorowy tematów/klas.',
    'baza-wektorowa-produkty': 'Indeks wektorowy produktów.',
    'baza-wektorowa-oswiadczenia': 'Indeks wektorowy treści oświadczeń/procedur.',
}
legenda['opis'] = legenda.apply(lambda r: legenda_map.get(r['tag'], r['opis']), axis=1)

legenda.to_csv(legenda_out, index=False)

pivot = unified.copy()
for t in technical_tags:
    pivot[t] = pivot['TAI - tagi'].fillna('').apply(lambda s: 1 if t in [x.strip() for x in s.split(',')] else 0)

pivot.to_csv(pivot_out, index=False)

print(f"Rows unified: {len(unified)} | unique tags: {len(unique_tags)} | technical: {len(technical_tags)}")